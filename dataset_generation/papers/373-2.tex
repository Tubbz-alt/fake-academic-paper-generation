\documentclass[../main.tex]{subfiles}
\begin{document}
    
\vspace{-5pt}
\section{Introduction}
Computer-assisted teaching offers the promise of personalized curricula that are tailored to the ability level and interests of every individual. 
Providing open access to the kinds of high-quality teaching that is currently only available to a small percentage of the world's population has the potential to transform education.
To date, subject areas such as mathematics \cite{koedinger1997intelligent,canfield2001aleks} and language learning \cite{von2013duolingo} have benefited from automated teaching systems. 
However, the problem of how to best teach visual expertise in fine-grained domains such as medical diagnosis and species identification is comparatively less well explored.   


In addition to the benefits to human learners from better teaching methods, automated systems could also take advantage of these improvements.
Access to expert time is often limited, and as a result, there is a need for better techniques to train crowd workers for image annotation tasks.
Once the workers have effectively learned the task they can provide higher quality labeled training data. 
This `closing of the loop' will enable us to take advantage of humans' ability to both generalize across different domains and cope with other nuisance factors such as pose and lighting changes. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\columnwidth]{figures/intro_2.pdf}
    \caption{A) The majority of existing machine teaching algorithms for visual categories only give feedback to the learner in the form of the ground truth class label. 
    B) It is much more informative to display the discriminative regions to help them to determine the categories present in the images. Here, we see explanations from our system highlighting the blank band on the Viceroy Butterfly and the white spots on the Queen Butterfly's wings. These are field markings commonly used to identify both species.}
    \label{interp_feedback_fig}
\end{figure}


Existing approaches to teaching visual knowledge typically pose the problem as choosing the most informative subset of images to show from a much larger set of possible options. 
One of the major limitations of this existing work is that they only give very limited feedback to students in the form of the class label, \eg \cite{singla2014near,johns2015}. 
In Fig. \ref{interp_feedback_fig}  A) we see an example of this label only feedback. 
Providing only the ground truth class label is a very limited amount of feedback compared to the rich explanations that one may receive from a human teacher. 
A human teacher would likely teach the student the specific parts and attributes in the image that are most discriminative for that particular class, Fig.~\ref{interp_feedback_fig}~B). 





Our hypothesis is that students that are taught with interpretable feedback will learn more effectively than those that only receive label feedback. 
Specifically, we propose a novel teaching algorithm that selects images that are both representative of the categories of interest and have explanations that can be easily interpreted. 
These explanations come in the form of feedback during teaching indicating the parts of the image that are important for successful classification. 
We show that it is possible to generate these explanations from existing labeled datasets, thus minimizing the need for additional annotations.
Through experiments on real human learners, we show that our joint selection of informative images and interpretable explanations results in better student learning and improved generalization at test time. 


\end{document}
